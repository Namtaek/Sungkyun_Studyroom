---
---

# 통계적 데이터분석 5회차

## 회귀분석의 기본

```{r}
library(dplyr) 
```

필요한 패키지를 불러왔다.

```{r}
data(delivery, package="robustbase")
```

데이터 불러오기

```{r}
delivery %>% head()
delivery %>% glimpse()  # dplyr package, 자료형 확인하기 좋음
delivery %>% summary
delivery %>% dim
```

### 단순선형회귀

```{r}
fit1 = lm(delTime ~ distance, data = delivery)
fit1 %>% summary()
```

결정계수가 0.79로 어느정도 적당하다. 회귀식이 전체 변동의 80%가량을 설명하고 있다. 또한 회귀식과 회귀계수의 유의성 모두 만족하고 있다.

```{r}
fit1 %>% cooks.distance()
```

여기서 보면 9번째 관측치의 cook's distance가 1 이상이다. 그래프를 봐보자.

```{r}
par(mfrow = c(2,2))
plot(fit1)
par(mfrow = c(1,1))
```

다른 그래프는 무시하고, 4번째 그래프를 확인하면, 9번 관측치가 영향점임을 확인할 수 있다. 회귀식을 시각화 해보면,

```{r}
plot(delivery$distance, delivery$delTime)
abline(fit1, lwd = 2)
```

오른쪽 맨 위의 점이다. 근데 전체적으로 봤을때 삭제해야할까 하는 의문이 남는다. 제거한 상태로 회귀분석을 돌려보자.

```{r}
delivery2 = delivery[-9,]
fit2 = lm(delTime ~ distance, data = delivery2)
fit2 %>% summary()
```

오히려 R제곱값이 떨어졌다.

```{r}
par(mfrow = c(2,2))
plot(fit2)
par(mfrow = c(1,1))
```

근데 다시 또 22번 관측치가 영향점으로 분류된다..... 그냥 회귀식을 통해 봐볼까?

```{r}
plot(delivery$distance, delivery$delTime)
abline(fit1, lwd = 2)
abline(fit2, lwd = 2, col = 'red')
```

빨간선이 영향점을 삭제했을때의 그래프다. 개인적으로 삭제하지 않았을때의 직선이 더 전체적인 경향을 잘 표현하고 있다고 생각하고, 실제로 R제곱값도 0.80 vs 0.60 정도이다. 여기서 Cook's Distance가 높게 나온 이유는? leverage 값이 크기 때문에!

따라서 그냥 기계적으로 영향점을 제거하는 것은 좋지 않다. 제거했을 때의 성능, 영향점으로 잡힌 이유를 설명하고 제거하는것이 바람직할 것이고, 지금은 제거하지 않는게 맞다.


### 다중회귀

```{r}
fit3 = lm(delTime ~ n.prod + distance, data = delivery)
#fit3 = lm(delTime ~., data = delivery)

# formula에 .을 찍으면 모든 변수를 다 쓰라는 뜻!

fit3 %>% summary
```

R제곱은 0.959, 수정R제곱은 0.955이다. 아까 단순회귀보다 R제곱값이 꽤나 상승했으니 적절한 변수였던 것 같다. 또한 회귀식과 회귀계수에 대한 검정 모두 만족한다.

```{r}
cooks.distance(fit3)
```

또 9번이 말썽이다.

```{r}
par(mfrow = c(2,2))
plot(fit3)
par(mfrow = c(1,1))
```

9번 관측치가 플랏상에서 cook distance가 1을 넘는것을 확인할 수 있다.

```{r}
fit4 = lm(delTime ~ n.prod + distance, data = delivery2)
fit4 %>% summary
```

근데 또 9번 삭제하니 설명력이 낮아진다. 똑같은 문제였겠지? 삭제하지 말자....

대신에 다른 방법을 써보자! 지금 배달 시간이 y고, 배달물품개수와 배달거리가 x인데, 배달거리가 멀수록 배달물품을 많이 주문하지 않을까? 즉, 둘 사이에 교호(상호)작용이 있지 않을까? 이를 잘 포착한다면 회귀식 성능에 진전이 있을 것이다.

```{r}
fit5 = lm(delTime ~ n.prod*distance, data = delivery) # 교호작용텀 고려
fit5 %>% summary
```

아까 수정 결정계수가 0.955였는데, 0.975로 증가했다. 개별 변수에도 보면, 현재 distance의 경우에는 유의수준 0.05에서 유의하지 않다고 하지만, 교호작용 텀이 있기 때문에 살려놓는것이 해석에 좋다. 전체 수정결정계수가 커졌기 때문에 남겨두어도 문제가 없다.

```{r}
par(mfrow = c(2,2))
plot(fit5)
par(mfrow = c(1,1))
```

아직 안배웠지만, 회귀가정중 정규성플랏도 아까보다 훨씬 잘 만족하고, cook's distance도 상대적으로 완화되었다.


### 로버스트 회귀

로버스트 회귀는 다루지 않았지만, 예시로서만 첨부해둡니다.

```{r}
library(MASS) # Huber's M
library(quantreg) # Median Regression
```

**huber's M**

시각화의 간편성을 위해 단순 선형회귀로 실시

```{r}
robust.fit = rlm(delTime ~ distance, data = delivery)
robust.fit %>% summary
```

그냥 회귀분석처럼 다양한 정보를 갖고 있기 어렵다...

```{r}
plot(delivery$distance, delivery$delTime)
abline(fit1, lwd = 1)
abline(robust.fit, lty = 2, lwd = 2, col = 'blue')
```

맨 오른쪽 위의 영향점의 가중치를 줄요서 전체 기울기를 감소시켰다.

**Median Regression**

```{r}
robust.fit2 = rq(delTime ~ distance, data = delivery)
robust.fit2 %>% summary
```

tau를 변화시킴에 따라 quantile regression으로 적용이 가능하다. 즉 tau=0.5이면 median이고, 아니면 다른 퀀타일값을 추정한다는 뜻!

이것도 lm 만큼 많은 정보를 지니고 있지 못하다...!!

```{r}
plot(delivery$distance, delivery$delTime)
abline(fit1, lwd = 1)
abline(robust.fit2, lty = 2, lwd = 2, col = 'blue')
```

아까보다 좀더 기울기가 줄어든 것을 확인할 수 있다.
